{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third round of feature engineering - adding a text mining feature\n",
    "The text mining feature uses the bag of words approach as representation for titles and abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# method to build the features\n",
    "# both params have to be .csv files\n",
    "def build_features(source_path,store_path):\n",
    "    \n",
    "    # get preprocessed data\n",
    "    df = pd.read_csv(source_path)\n",
    "\n",
    "    # fill nan-values for references with empty list\n",
    "    df.references.fillna(\"[]\", inplace=True)\n",
    "\n",
    "    # change references column type from string into array\n",
    "    df.references = df.references.apply(literal_eval)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # keyword matching feature\n",
    "\n",
    "    # add new features to dataframe\n",
    "    addKeywordFeature(df, \"literature review\", \"title\", \"title_literaturereview\")\n",
    "    addKeywordFeature(df, \"literature review\", \"abstract\", \"abstract_literaturereview\")\n",
    "    addKeywordFeature(df, \"review\", \"title\", \"title_review\")\n",
    "    addKeywordFeature(df, \"review\", \"abstract\", \"abstract_review\")\n",
    "    addKeywordFeature(df, \"survey\", \"title\", \"title_survey\")\n",
    "    addKeywordFeature(df, \"survey\", \"abstract\", \"abstract_survey\")\n",
    "    addKeywordFeature(df, \"experiment\", \"title\", \"title_experiment\")\n",
    "    addKeywordFeature(df, \"experiment\", \"abstract\", \"abstract_experiment\")\n",
    "    addKeywordFeature(df, \"interview\", \"title\", \"title_interview\")\n",
    "    addKeywordFeature(df, \"interview\", \"abstract\", \"abstract_interview\")\n",
    "    addKeywordFeature(df, \"case study\", \"title\", \"title_casestudy\")\n",
    "    addKeywordFeature(df, \"case study\", \"abstract\", \"abstract_casestudy\")\n",
    "    addKeywordFeature(df, \"questionnaire\", \"title\", \"title_questionnaire\")\n",
    "    addKeywordFeature(df, \"questionnaire\", \"abstract\", \"abstract_questionnaire\")\n",
    "    addKeywordFeature(df, \"design science\", \"title\", \"title_designscience\")\n",
    "    addKeywordFeature(df, \"design science\", \"abstract\", \"abstract_designscience\")\n",
    "    addKeywordFeature(df, \"meta-analysis\", \"title\", \"title_metaanalysis\")\n",
    "    addKeywordFeature(df, \"meta-analysis\", \"abstract\", \"abstract_metaanalysis\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # method paper matching feature\n",
    "\n",
    "    # read in list of literature review method papers and extract dois\n",
    "    df_method_papers = pd.read_csv(\"../data/external/lr-method-papers.csv\", usecols=[\"doi\"])\n",
    "    df_method_papers.dropna(inplace = True)\n",
    "    method_papers = df_method_papers['doi'].tolist()\n",
    "    \n",
    "    reference_count = []\n",
    "\n",
    "    # count, how many method papers are mentioned in each paper\n",
    "    for index, row in df.loc[:, [\"references\"]].iterrows():\n",
    "        counter = 0\n",
    "        for doi in df[\"references\"][index]:\n",
    "            if doi in method_papers:\n",
    "                counter += 1\n",
    "        reference_count.append(counter)\n",
    "    \n",
    "    # add the counters to the dataframe as a new column\n",
    "    df.insert(loc=len(df.columns), column=\"references_count\", value=reference_count)\n",
    "\n",
    "    \n",
    "    \n",
    "    # text mining feature with bag of words\n",
    "\n",
    "    # change nan-values to empty strings\n",
    "    df.abstract.fillna(\"\", inplace=True)\n",
    "    df.title.fillna(\"\", inplace=True)\n",
    "\n",
    "    # clean abstracts and titles\n",
    "    df[\"clean_abstracts\"] = df.abstract.map(clean_text, na_action=\"ignore\")\n",
    "    df[\"clean_titles\"] = df.title.map(clean_text, na_action=\"ignore\")\n",
    "\n",
    "    # count vectorizer for bag of words\n",
    "    bow_abstracts = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
    "    bow_titles = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
    "\n",
    "    # fit vocabulary\n",
    "    abstract_matrix = bow_abstracts.fit_transform(df.clean_abstracts)\n",
    "    title_matrix = bow_titles.fit_transform(df.clean_titles)\n",
    "\n",
    "    # variance threshold feature selection\n",
    "    selector = VarianceThreshold(threshold=(.99*(1-.99)))\n",
    "    abstract_matrix = selector.fit_transform(abstract_matrix)\n",
    "    title_matrix = selector.fit_transform(title_matrix)\n",
    "\n",
    "    # convert sparse matrix into dataframe\n",
    "    df_abstracts = pd.DataFrame.sparse.from_spmatrix(abstract_matrix)\n",
    "    df_titles = pd.DataFrame.sparse.from_spmatrix(title_matrix)\n",
    "\n",
    "    # change column names to prepare for concat\n",
    "    df_titles.rename(columns=lambda x: str(x) + \"_title\", inplace=True)\n",
    "    df_abstracts.rename(columns=lambda x: str(x) + \"_abstracts\", inplace=True)\n",
    "\n",
    "    # concat all dataframes to single dataframe\n",
    "    df = pd.concat([df, df_titles, df_abstracts], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # drop columns that are not needed anymore\n",
    "    df.drop(['title', 'abstract', 'references', 'clean_titles', 'clean_abstracts'], axis = 1, inplace = True)\n",
    "\n",
    "    # store resulting dataframe as csv\n",
    "    df.to_csv(store_path, index=False)\n",
    "    \n",
    "    \n",
    "# helper function to add keyword-matching features\n",
    "def addKeywordFeature(df, keyword, column, col_name):\n",
    "    toAdd = []\n",
    "    if column == \"abstract\":\n",
    "        for index, row in df.loc[:, [column]].iterrows():\n",
    "            if pd.isna(df[column][index]):\n",
    "                toAdd.append(2)\n",
    "            elif keyword in row.abstract.lower():\n",
    "                toAdd.append(1)\n",
    "            else:\n",
    "                toAdd.append(0)\n",
    "        df.insert(loc=len(df.columns), column=col_name, value=toAdd)\n",
    "    elif column == \"title\":\n",
    "        for index, row in df.loc[:, [column]].iterrows():\n",
    "            if pd.isna(df[column][index]):\n",
    "                toAdd.append(2)\n",
    "            elif keyword in row.title.lower():\n",
    "                toAdd.append(1)\n",
    "            else:\n",
    "                toAdd.append(0)\n",
    "        df.insert(loc=len(df.columns), column=col_name, value=toAdd)\n",
    "\n",
    "\n",
    "\n",
    "# clean text helper function for bow\n",
    "def clean_text(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove punctuation and multiple spaces\n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \" \", text\n",
    "    )\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build features for original dataset\n",
    "build_features('../data/interim/data_original.csv','../data/processed/original_dataset/data_tm.csv')\n",
    "\n",
    "# build features for extended dataset\n",
    "build_features('../data/interim/data_extended.csv','../data/processed/extended_dataset/data_tm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
