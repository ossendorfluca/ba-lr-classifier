{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split, parameter tuning, cross validation, final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning, FitFailedWarning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FitFailedWarning)\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(source_file):\n",
    "    df = pd.read_csv(source_file)\n",
    "    X = df.drop(['literature_review'], axis=1)\n",
    "    y = df['literature_review']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning and testing\n",
    "- various parameters are tested for each algorithm using sklearn's GridSearchCV\n",
    "- the parameters are evaluated using cross validation\n",
    "- the best parameters are used for training the model\n",
    "- the model is then tested on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_params(X_train,y_train,X_test,y_test,pipeline,params):\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=params, scoring=['f1','recall','precision'],cv=5, refit='f1')\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f\"     f1: {f1}\\n     recall: {recall}\\n      precision: {precision}\")\n",
    "    return f1, recall, precision\n",
    "\n",
    "def train_and_test(source_path):\n",
    "    X_train, X_test, y_train, y_test = split(source_path)\n",
    "    f1_scores = {}\n",
    "    recall_scores = {}\n",
    "    precision_scores = {}\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_pipeline = Pipeline([('scaler', StandardScaler()),('lr', LogisticRegression(max_iter=200))])\n",
    "    lr_params = {'lr__penalty':['l1','l2'], \n",
    "                'lr__C':[1, 10, 100, 1000],\n",
    "                'lr__class_weight': [None, 'balanced']}\n",
    "    print('Logistic Regression:')\n",
    "    f1, recall, precision = tune_params(X_train, y_train, X_test, y_test, lr_pipeline, lr_params)\n",
    "    f1_scores['LR'] = f1\n",
    "    recall_scores['LR'] = recall\n",
    "    precision_scores['LR'] = precision\n",
    "\n",
    "    # Support Vector Machines\n",
    "    svm_pipeline = Pipeline([('scaler', StandardScaler()),('svm', SVC())])\n",
    "    svm_params = {'svm__C': [0.1, 1, 10],  \n",
    "                'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "                'svm__kernel': ['rbf'],\n",
    "                'svm__class_weight': [None, 'balanced']}\n",
    "    print('Support Vector Machines:')\n",
    "    f1, recall, precision = tune_params(X_train, y_train, X_test, y_test, svm_pipeline, svm_params)\n",
    "    f1_scores['SVM'] = f1\n",
    "    recall_scores['SVM'] = recall\n",
    "    precision_scores['SVM'] = precision\n",
    "\n",
    "    # Naive Bayes\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print('Naive Bayes:')\n",
    "    print(f\"     f1: {f1}\\n     recall: {recall}\\n      precision: {precision}\")\n",
    "    f1_scores['NB'] = f1\n",
    "    recall_scores['NB'] = recall\n",
    "    precision_scores['NB'] = precision\n",
    "   \n",
    "    # Decision Trees\n",
    "    dt_pipeline = Pipeline([('dt', DecisionTreeClassifier())])\n",
    "    dt_params = {'dt__criterion': ['gini', 'entropy'], \n",
    "                'dt__max_depth':range(1,10),\n",
    "                'dt__class_weight': [None, 'balanced']}\n",
    "    print('Decision Trees:')\n",
    "    f1, recall, precision = tune_params(X_train, y_train, X_test, y_test, dt_pipeline, dt_params)\n",
    "    f1_scores['DT'] = f1\n",
    "    recall_scores['DT'] = recall\n",
    "    precision_scores['DT'] = precision\n",
    "\n",
    "    # Random Forest\n",
    "    rf_pipeline = Pipeline([('rf', RandomForestClassifier())])\n",
    "    rf_params = {'rf__bootstrap': [True, False],\n",
    "                 'rf__max_depth': [3, 6, 9, None],\n",
    "                 'rf__max_features': ['auto', 'sqrt'],\n",
    "                 'rf__n_estimators': [25, 50, 100, 150],\n",
    "                 'rf__class_weight': [None, 'balanced']}\n",
    "    print(f'Random Forest:')\n",
    "    f1, recall, precision = tune_params(X_train, y_train, X_test, y_test, rf_pipeline, rf_params)\n",
    "    f1_scores['RF'] = f1\n",
    "    recall_scores['RF'] = recall\n",
    "    precision_scores['RF'] = precision\n",
    "\n",
    "\n",
    "    # k-nearest neighbor\n",
    "    knn_pipeline = Pipeline([('scaler', StandardScaler()),('knn', KNeighborsClassifier())])\n",
    "    knn_params = {'knn__n_neighbors': range(1,10),  \n",
    "                'knn__weights': ['uniform', 'distance']}\n",
    "    print(f'K-nearest neighbor:')\n",
    "    f1, recall, precision = tune_params(X_train, y_train, X_test, y_test, knn_pipeline, knn_params)\n",
    "    f1_scores['kNN'] = f1\n",
    "    recall_scores['kNN'] = recall\n",
    "    precision_scores['kNN'] = precision\n",
    "    \n",
    "    # Balanced Random Forest\n",
    "    brf_pipeline = imbpipeline([('brf', BalancedRandomForestClassifier())])\n",
    "    brf_params = {'brf__bootstrap': [True, False],\n",
    "                 'brf__max_depth': [3, 6, 9, None],\n",
    "                 'brf__max_features': ['auto', 'sqrt'],\n",
    "                 'brf__n_estimators': [25, 50, 100, 150],\n",
    "                 'brf__class_weight': [None, 'balanced']}\n",
    "    print(f'Balanced Random Forest:')\n",
    "    f1, recall, precision = tune_params(X_train, y_train, X_test, y_test, brf_pipeline, brf_params)\n",
    "    f1_scores['BRF'] = f1\n",
    "    recall_scores['BRF'] = recall\n",
    "    precision_scores['BRF'] = precision\n",
    "\n",
    "    return f1_scores, recall_scores, precision_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph for visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(f1, recall, precision):\n",
    "    \n",
    "    del f1['NB']\n",
    "    del f1['kNN']\n",
    "    del recall['NB']\n",
    "    del recall['kNN']\n",
    "    del precision['NB']\n",
    "    del precision['kNN']\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.bar(x=[0,5,10,15,20], height=list(f1.values()), width=0.9, color=\"tomato\", label=\"f1\")\n",
    "    plt.bar(x=[1,6,11,16,21], height=list(precision.values()), width=0.9, color=\"dodgerblue\", label=\"precision\")\n",
    "    plt.bar(x=[2,7,12,17,22], height=list(recall.values()), width=0.9, color=\"lime\", label=\"recall\")\n",
    "\n",
    "    plt.xlabel(\"algorithm\")\n",
    "    plt.ylabel(\"metric score\")\n",
    "\n",
    "    plt.xticks(ticks=[1.5, 6.5, 11.5, 16.5, 21.5], labels=list(f1.keys()), rotation=45)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All feature combinations are tested on both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- - - original dataset, keywords feature - - -\")\n",
    "f1_scores, recall_scores, precision_scores = train_and_test(\"../data/processed/original_dataset/data_key.csv\")\n",
    "make_graph(f1_scores, recall_scores, precision_scores)\n",
    "\n",
    "print(\"- - - original dataset, references feature - - -\")\n",
    "f1_scores, recall_scores, precision_scores = train_and_test(\"../data/processed/original_dataset/data_ref.csv\")\n",
    "make_graph(f1_scores, recall_scores, precision_scores)\n",
    "\n",
    "print(\"- - - original dataset, text mining feature - - -\")\n",
    "f1_scores, recall_scores, precision_scores = train_and_test(\"../data/processed/original_dataset/data_tm.csv\")\n",
    "make_graph(f1_scores, recall_scores, precision_scores)\n",
    "\n",
    "print(\"- - - extended dataset, keywords feature - - -\")\n",
    "f1_scores, recall_scores, precision_scores = train_and_test(\"../data/processed/extended_dataset/data_key.csv\")\n",
    "make_graph(f1_scores, recall_scores, precision_scores)\n",
    "\n",
    "print(\"- - - extended dataset, references feature - - -\")\n",
    "f1_scores, recall_scores, precision_scores = train_and_test(\"../data/processed/extended_dataset/data_ref.csv\")\n",
    "make_graph(f1_scores, recall_scores, precision_scores)\n",
    "\n",
    "print(\"- - - extended dataset, text mining feature - - -\")\n",
    "f1_scores, recall_scores, precision_scores = train_and_test(\"../data/processed/extended_dataset/data_tm.csv\")\n",
    "make_graph(f1_scores, recall_scores, precision_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
