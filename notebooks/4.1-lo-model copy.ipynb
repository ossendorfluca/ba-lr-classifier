{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting count vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:823: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE #-> oversampling technique\n",
    "\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# get interim data\n",
    "df = pd.read_csv(\"../data/interim/data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# fill nan-values for references with empty list\n",
    "df.references.fillna(\"[]\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# change references type from string into array\n",
    "df.references = df.references.apply(literal_eval)\n",
    "\n",
    "\n",
    "\n",
    "# keyword-matching features\n",
    "\n",
    "def addKeywordFeature(df, keyword, column, col_name):\n",
    "    toAdd = []\n",
    "    if column == \"abstract\":\n",
    "        for index, row in df.loc[:, [column]].iterrows():\n",
    "            if pd.isna(df[column][index]):\n",
    "                toAdd.append(2)\n",
    "            elif keyword in row.abstract.lower():\n",
    "                toAdd.append(1)\n",
    "            else:\n",
    "                toAdd.append(0)\n",
    "        df.insert(loc=len(df.columns), column=col_name, value=toAdd)\n",
    "    elif column == \"title\":\n",
    "        for index, row in df.loc[:, [column]].iterrows():\n",
    "            if pd.isna(df[column][index]):\n",
    "                toAdd.append(2)\n",
    "            elif keyword in row.title.lower():\n",
    "                toAdd.append(1)\n",
    "            else:\n",
    "                toAdd.append(0)\n",
    "        df.insert(loc=len(df.columns), column=col_name, value=toAdd)\n",
    "\n",
    "addKeywordFeature(df, \"literature review\", \"title\", \"title_literaturereview\")\n",
    "addKeywordFeature(df, \"literature review\", \"abstract\", \"abstract_literaturereview\")\n",
    "addKeywordFeature(df, \"review\", \"title\", \"title_review\")\n",
    "addKeywordFeature(df, \"review\", \"abstract\", \"abstract_review\")\n",
    "addKeywordFeature(df, \"survey\", \"title\", \"title_survey\")\n",
    "addKeywordFeature(df, \"survey\", \"abstract\", \"abstract_survey\")\n",
    "addKeywordFeature(df, \"experiment\", \"title\", \"title_experiment\")\n",
    "addKeywordFeature(df, \"experiment\", \"abstract\", \"abstract_experiment\")\n",
    "addKeywordFeature(df, \"interview\", \"title\", \"title_interview\")\n",
    "addKeywordFeature(df, \"interview\", \"abstract\", \"abstract_interview\")\n",
    "addKeywordFeature(df, \"case study\", \"title\", \"title_casestudy\")\n",
    "addKeywordFeature(df, \"case study\", \"abstract\", \"abstract_casestudy\")\n",
    "addKeywordFeature(df, \"questionnaire\", \"title\", \"title_questionnaire\")\n",
    "addKeywordFeature(df, \"questionnaire\", \"abstract\", \"abstract_questionnaire\")\n",
    "addKeywordFeature(df, \"design science\", \"title\", \"title_designscience\")\n",
    "addKeywordFeature(df, \"design science\", \"abstract\", \"abstract_designscience\")\n",
    "\n",
    "\n",
    "\n",
    "# method paper matching feature\n",
    "\n",
    "# read in list of literature review method papers and extract dois\n",
    "df_method_papers = pd.read_csv(\"../data/external/lr-method-papers.csv\", usecols=[\"doi\"])\n",
    "df_method_papers.dropna(inplace = True)\n",
    "method_papers = df_method_papers['doi'].tolist()\n",
    "\n",
    "reference_count = []\n",
    "\n",
    "for index, row in df.loc[:, [\"references\"]].iterrows():\n",
    "    counter = 0\n",
    "    for doi in df[\"references\"][index]:\n",
    "        if doi in method_papers:\n",
    "            counter += 1\n",
    "    reference_count.append(counter)\n",
    "    \n",
    "df.insert(loc=len(df.columns), column=\"references_count\", value=reference_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# text mining feature with bag of words\n",
    "\n",
    "df.abstract.fillna(\"\", inplace=True)\n",
    "df.title.fillna(\"\", inplace=True)\n",
    "\n",
    "# clean text helper function\n",
    "def clean_text(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove punctuation and multiple spaces\n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \" \", text\n",
    "    )\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# clean abstracts and titles\n",
    "df[\"clean_abstracts\"] = df.abstract.map(clean_text, na_action=\"ignore\")\n",
    "df[\"clean_titles\"] = df.title.map(clean_text, na_action=\"ignore\")\n",
    "\n",
    "# count vectorizer for bag of words\n",
    "print(\"starting count vectorizer\")\n",
    "bow_abstracts = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
    "bow_titles = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
    "\n",
    "# fit vocabulary\n",
    "abstract_matrix = bow_abstracts.fit_transform(df.clean_abstracts)\n",
    "title_matrix = bow_titles.fit_transform(df.clean_titles)\n",
    "\n",
    "# variance threshold feature selection\n",
    "#print(\"variance threshold\")\n",
    "#selector = VarianceThreshold()\n",
    "#abstract_matrix = selector.fit_transform(abstract_matrix)\n",
    "#title_matrix = selector.fit_transform(title_matrix)\n",
    "\n",
    "# convert sparse matrix into dataframe\n",
    "df_abstracts = pd.DataFrame.sparse.from_spmatrix(abstract_matrix)\n",
    "df_titles = pd.DataFrame.sparse.from_spmatrix(title_matrix)\n",
    "\n",
    "# change column names to prepare for concat\n",
    "df_titles.rename(columns=lambda x: str(x) + \"_title\", inplace=True)\n",
    "df_abstracts.rename(columns=lambda x: str(x) + \"_abstracts\", inplace=True)\n",
    "\n",
    "# concat all dataframes to single dataframe\n",
    "df_final = pd.concat([df, df_titles, df_abstracts], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_final.drop(['title', 'abstract', 'references', 'clean_titles', 'clean_abstracts'], axis = 1, inplace = True)\n",
    "\n",
    "df = df_final\n",
    "\n",
    "X = df.drop(['literature_review'], axis=1)\n",
    "y = df['literature_review']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=42)\n",
    "\n",
    "# oversampling with SMOTE\n",
    "oversample = SMOTE(k_neighbors=2)\n",
    "over_X, over_y = oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "\n",
    "models = {}\n",
    "models['Logistic Regression'] = LogisticRegression(class_weight='balanced')\n",
    "models['Support Vector Machines'] = SVC(class_weight='balanced')\n",
    "models['Naive Bayes'] = BernoulliNB()\n",
    "models['Decision Trees'] = DecisionTreeClassifier(class_weight='balanced')\n",
    "models['Random Forest'] = RandomForestClassifier(class_weight='balanced')\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()\n",
    "models['BRF'] = BalancedRandomForestClassifier()\n",
    "\n",
    "accuracy = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "conf_mat = {}\n",
    "f1 = {}\n",
    "\n",
    "for key in models.keys():\n",
    "    accuracy[key] = np.mean(cross_val_score(models[key], X_train, y_train, scoring=\"accuracy\"))\n",
    "    precision[key] = np.mean(cross_val_score(models[key], X_train, y_train, scoring=\"precision\"))\n",
    "    recall[key] = np.mean(cross_val_score(models[key], X_train, y_train, scoring=\"recall\"))\n",
    "    f1[key] = np.mean(cross_val_score(models[key], X_train, y_train, scoring=\"f1\"))\n",
    "    y_pred = cross_val_predict(models[key], X_train, y_train)\n",
    "    conf_mat[key] = confusion_matrix(y_train, y_pred)\n",
    "    print(key)\n",
    "    print(f\"f1: {f1[key]}, precision: {precision[key]}, recall: {recall[key]}, accuracy: {accuracy[key]}\")\n",
    "\n",
    "models['SMOTE'] = RandomForestClassifier()\n",
    "accuracy['SMOTE'] = np.mean(cross_val_score(models['SMOTE'], over_X, over_y, scoring=\"accuracy\"))\n",
    "precision['SMOTE'] = np.mean(cross_val_score(models['SMOTE'], over_X, over_y, scoring=\"precision\"))\n",
    "recall['SMOTE'] = np.mean(cross_val_score(models['SMOTE'], over_X, over_y, scoring=\"recall\"))\n",
    "f1['SMOTE'] = np.mean(cross_val_score(models['SMOTE'], over_X, over_y, scoring=\"f1\"))\n",
    "y_pred = cross_val_predict(models['SMOTE'], over_X, over_y)\n",
    "conf_mat['SMOTE'] = confusion_matrix(over_y, y_pred)\n",
    "print(\"SMOTE\")\n",
    "print(f\"f1: {f1['SMOTE']}, precision: {precision['SMOTE']}, recall: {recall['SMOTE']}, accuracy: {accuracy['SMOTE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
